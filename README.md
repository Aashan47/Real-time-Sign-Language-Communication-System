# ğŸ¤Ÿ Real-time Sign Language Communication System

A cross-platform application that enables **real-time, bidirectional communication** between hearing and hearing-impaired individuals through **sign language recognition** and **speech synthesis**.

This system bridges the communication gap by combining **computer vision**, **machine learning**, and **speech technologies** within an intuitive, Flutter-powered user experience.

---

## ğŸš€ Features

- ğŸ”¤ **Real-time Sign Language Detection**  
  Detects hand gestures using machine learning and translates them to text and speech.

- ğŸ—£ï¸ **Speech-to-Text & Text-to-Sign Conversion**  
  Converts voice input to sign language visualizations for better accessibility.

- ğŸ“± **Cross-Platform Support**  
  Built with Flutter to support Android, iOS, Web, Windows, macOS, and Linux.

- ğŸŒ **Ngrok-powered Backend Integration**  
  Python backend uses `ngrok` tunneling for seamless real-time interaction.

---

## ğŸ§  Tech Stack

### Frontend (`equispeak/`)
- [Flutter](https://flutter.dev/) (Dart)
- Platform Support: Android, iOS, Web, Desktop
- Asset-based animations or sign visuals

### Backend (`Backend implementation/`)
- Python 3.x
- Likely libraries: OpenCV, TensorFlow/MediaPipe
- Local server via Flask or FastAPI
- Ngrok for public URL tunneling

---

## ğŸ“ Project Structure

â”œâ”€â”€ equispeak/ # Flutter front-end
â”‚ â”œâ”€â”€ lib/ # Dart source code
â”‚ â”œâ”€â”€ android/ ios/ web/ # Platform-specific code
â”‚ â”œâ”€â”€ assets/ # Images, animations, videos
â”‚ â””â”€â”€ pubspec.yaml # Flutter dependencies

â”œâ”€â”€ Backend implementation/ # Python-based ML backend
â”‚ â”œâ”€â”€ models/ # Pretrained or custom ML models
â”‚ â”œâ”€â”€ src/ # Backend utilities and helpers
â”‚ â”œâ”€â”€ main.py / server.py # API endpoints and inference logic
â”‚ â””â”€â”€ requirements.txt # Python dependencies

## âš™ï¸ Getting Started

### ğŸ”§ Frontend Setup

```bash
cd equispeak
flutter pub get
flutter run

ğŸ§  Backend Setup

cd "Backend implementation"
pip install -r requirements.txt
python server.py

To expose the backend using ngrok:
ngrok http 5000

## ğŸ“Œ Use Cases
This system is ideal for:

Educational institutions

Customer service counters

Healthcare environments

Public-facing offices

One-on-one communication

Anywhere sign language users need instant understanding, this app ensures inclusive communication.

## ğŸ‘¤ Author
Aashan Javed
GitHub: @Aashan47

## ğŸ“Œ License
This project is open source and available under the MIT License.

## ğŸ™Œ Future Improvements (Suggested)
Add support for multiple sign languages (e.g., BSL, ISL)

Train with real-world gesture datasets for higher accuracy

Implement offline mode using on-device ML

Include customizable avatars for animated sign display
